{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c879503",
   "metadata": {},
   "source": [
    "### RAG Pipelines- Data Ingestion to Vector DB Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6377b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b88997a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaibhavarde/Desktop/AgentKrish/RAG-Tutorials/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a312dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 PDF files to process\n",
      "\n",
      "Processing: LookerCertificate.pdf\n",
      "  ✓ Loaded 1 pages\n",
      "\n",
      "Processing: RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf\n",
      "  ✓ Loaded 1 pages\n",
      "\n",
      "Total documents loaded: 2\n"
     ]
    }
   ],
   "source": [
    "### Read all the pdf's inside the directory\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all PDF files in a directory\"\"\"\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "    \n",
    "    # Find all PDF files recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "    \n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "            \n",
    "            all_documents.extend(documents)\n",
    "            print(f\"  ✓ Loaded {len(documents)} pages\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error: {e}\")\n",
    "    \n",
    "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "# Process all PDFs in the data directory\n",
    "all_pdf_documents = process_all_pdfs(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96748c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '2024-07-18T13:03:49+00:00', 'moddate': '2024-07-18T13:03:49+00:00', 'source': '../data/pdf/LookerCertificate.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'LookerCertificate.pdf', 'file_type': 'pdf'}, page_content=''),\n",
       " Document(metadata={'producer': 'Skia/PDF m141', 'creator': 'FlowCV - https://flowcv.com', 'creationdate': '2025-11-19T11:01:31+00:00', 'moddate': '2025-11-19T11:01:31+00:00', 'keywords': 'FlowCV – Online Resume Builder – https://flowcv.com', 'source': '../data/pdf/RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf', 'file_type': 'pdf'}, page_content='RUSHIKESH MORE\\npython developer\\nrushismore7777@gmail.com\\n \\n+919067717776\\n \\nKolhapur,Maharashtra,India\\n \\nlinkedin.com/in/rushikesh-more-2879182a8\\n \\ngithub.com/RushikeshMore66\\n \\nPROFILE\\nPython Developer with a strong foundation in Computer Science and AI/ML. Skilled in FastAPI, LangChain,\\nMCP servers, and LLM integrations for building intelligent applications. Currently expanding my expertise\\nin advanced Python development and modern AI frameworks. Passionate about creating scalable AI\\nsolutions and continuously growing as a developer.\\nSKILLS\\n•Programming languages : Python\\n•Cloud : Git\\n•Frameworks & Tools : FastAPI, Streamlit\\n•Soft skill : Attention To Detail , Creative Thinking ,Team Collaboration, Time Management\\nCERTIFICATES\\nAI Agents : Google\\nPython coder badge : Google\\nPROJECTS\\nRealtime chatting Application\\nDeveloped a real-time chat application using FastAPI, Firebase, and React with secure authentication and \\ninstant messaging features. Integrated OpenAI to provide AI-powered smart responses and chat assistance \\nfor an enhanced user experience.\\nShowroom Management System\\nDeveloped an AI-enhanced showroom management system using FastAPI as the backend and Streamlit for \\nan intuitive user interface. Integrated MCP servers (Context7) and Gemini CLI to enable advanced AI-\\ndriven task automation, data retrieval, and intelligent decision support. Implemented tools and workflows \\nusing Speckit to define system rules, plans, and operations, enabling streamlined inventory management, \\nproduct tracking, customer assistance, and staff task coordination. \\nEDUCATION\\nBachelor of Engineering (B.E.) - Artificial Intelligence and Machine Learning\\nSavitribai Phule Pune University, Pune\\n08/2022 – 07/2025\\nPune,India\\nPost Graduate (Diploma)- Computer Science\\nMaharashtra State Board Of Technical Education\\n07/2020 – 06/2022\\nKolhapur,Maharashtra')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fab6b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Text splitting get into chunks\n",
    "\n",
    "def split_documents(documents,chunk_size=1000,chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performance\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "    \n",
    "    # Show example of a chunk\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    \n",
    "    return split_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7b75a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 2 documents into 3 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: RUSHIKESH MORE\n",
      "python developer\n",
      "rushismore7777@gmail.com\n",
      " \n",
      "+919067717776\n",
      " \n",
      "Kolhapur,Maharashtra,India\n",
      " \n",
      "linkedin.com/in/rushikesh-more-2879182a8\n",
      " \n",
      "github.com/RushikeshMore66\n",
      " \n",
      "PROFILE\n",
      "Python Developer...\n",
      "Metadata: {'producer': 'Skia/PDF m141', 'creator': 'FlowCV - https://flowcv.com', 'creationdate': '2025-11-19T11:01:31+00:00', 'moddate': '2025-11-19T11:01:31+00:00', 'keywords': 'FlowCV – Online Resume Builder – https://flowcv.com', 'source': '../data/pdf/RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf', 'file_type': 'pdf'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m141', 'creator': 'FlowCV - https://flowcv.com', 'creationdate': '2025-11-19T11:01:31+00:00', 'moddate': '2025-11-19T11:01:31+00:00', 'keywords': 'FlowCV – Online Resume Builder – https://flowcv.com', 'source': '../data/pdf/RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf', 'file_type': 'pdf'}, page_content='RUSHIKESH MORE\\npython developer\\nrushismore7777@gmail.com\\n \\n+919067717776\\n \\nKolhapur,Maharashtra,India\\n \\nlinkedin.com/in/rushikesh-more-2879182a8\\n \\ngithub.com/RushikeshMore66\\n \\nPROFILE\\nPython Developer with a strong foundation in Computer Science and AI/ML. Skilled in FastAPI, LangChain,\\nMCP servers, and LLM integrations for building intelligent applications. Currently expanding my expertise\\nin advanced Python development and modern AI frameworks. Passionate about creating scalable AI\\nsolutions and continuously growing as a developer.\\nSKILLS\\n•Programming languages : Python\\n•Cloud : Git\\n•Frameworks & Tools : FastAPI, Streamlit\\n•Soft skill : Attention To Detail , Creative Thinking ,Team Collaboration, Time Management\\nCERTIFICATES\\nAI Agents : Google\\nPython coder badge : Google\\nPROJECTS\\nRealtime chatting Application\\nDeveloped a real-time chat application using FastAPI, Firebase, and React with secure authentication and'),\n",
       " Document(metadata={'producer': 'Skia/PDF m141', 'creator': 'FlowCV - https://flowcv.com', 'creationdate': '2025-11-19T11:01:31+00:00', 'moddate': '2025-11-19T11:01:31+00:00', 'keywords': 'FlowCV – Online Resume Builder – https://flowcv.com', 'source': '../data/pdf/RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf', 'file_type': 'pdf'}, page_content='AI Agents : Google\\nPython coder badge : Google\\nPROJECTS\\nRealtime chatting Application\\nDeveloped a real-time chat application using FastAPI, Firebase, and React with secure authentication and \\ninstant messaging features. Integrated OpenAI to provide AI-powered smart responses and chat assistance \\nfor an enhanced user experience.\\nShowroom Management System\\nDeveloped an AI-enhanced showroom management system using FastAPI as the backend and Streamlit for \\nan intuitive user interface. Integrated MCP servers (Context7) and Gemini CLI to enable advanced AI-\\ndriven task automation, data retrieval, and intelligent decision support. Implemented tools and workflows \\nusing Speckit to define system rules, plans, and operations, enabling streamlined inventory management, \\nproduct tracking, customer assistance, and staff task coordination. \\nEDUCATION\\nBachelor of Engineering (B.E.) - Artificial Intelligence and Machine Learning\\nSavitribai Phule Pune University, Pune\\n08/2022 – 07/2025\\nPune,India'),\n",
       " Document(metadata={'producer': 'Skia/PDF m141', 'creator': 'FlowCV - https://flowcv.com', 'creationdate': '2025-11-19T11:01:31+00:00', 'moddate': '2025-11-19T11:01:31+00:00', 'keywords': 'FlowCV – Online Resume Builder – https://flowcv.com', 'source': '../data/pdf/RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf', 'file_type': 'pdf'}, page_content='EDUCATION\\nBachelor of Engineering (B.E.) - Artificial Intelligence and Machine Learning\\nSavitribai Phule Pune University, Pune\\n08/2022 – 07/2025\\nPune,India\\nPost Graduate (Diploma)- Computer Science\\nMaharashtra State Board Of Technical Education\\n07/2020 – 06/2022\\nKolhapur,Maharashtra')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks=split_documents(all_pdf_documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe92ea",
   "metadata": {},
   "source": [
    "### embedding And vectorStoreDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3ae3031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "543614c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x12d3f8a50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using SentenceTransformer\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialize the embedding manager\n",
    "        \n",
    "        Args:\n",
    "            model_name: HuggingFace model name for sentence embeddings\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "        \n",
    "        Args:\n",
    "            texts: List of text strings to embed\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "## initialize the embedding manager\n",
    "\n",
    "embedding_manager=EmbeddingManager()\n",
    "embedding_manager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c9e3b",
   "metadata": {},
   "source": [
    "### VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c276d1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection: pdf_documents\n",
      "Existing documents in collection: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x12cd35850>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a ChromaDB vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "        \n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            # Create persistent ChromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            \n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "        \n",
    "        Args:\n",
    "            documents: List of LangChain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "        \n",
    "        # Prepare data for ChromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "        \n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique ID\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "            \n",
    "            # Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "            \n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "            \n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "        \n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vectorstore=VectorStore()\n",
    "vectorstore\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d5d2c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m141', 'creator': 'FlowCV - https://flowcv.com', 'creationdate': '2025-11-19T11:01:31+00:00', 'moddate': '2025-11-19T11:01:31+00:00', 'keywords': 'FlowCV – Online Resume Builder – https://flowcv.com', 'source': '../data/pdf/RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf', 'file_type': 'pdf'}, page_content='RUSHIKESH MORE\\npython developer\\nrushismore7777@gmail.com\\n \\n+919067717776\\n \\nKolhapur,Maharashtra,India\\n \\nlinkedin.com/in/rushikesh-more-2879182a8\\n \\ngithub.com/RushikeshMore66\\n \\nPROFILE\\nPython Developer with a strong foundation in Computer Science and AI/ML. Skilled in FastAPI, LangChain,\\nMCP servers, and LLM integrations for building intelligent applications. Currently expanding my expertise\\nin advanced Python development and modern AI frameworks. Passionate about creating scalable AI\\nsolutions and continuously growing as a developer.\\nSKILLS\\n•Programming languages : Python\\n•Cloud : Git\\n•Frameworks & Tools : FastAPI, Streamlit\\n•Soft skill : Attention To Detail , Creative Thinking ,Team Collaboration, Time Management\\nCERTIFICATES\\nAI Agents : Google\\nPython coder badge : Google\\nPROJECTS\\nRealtime chatting Application\\nDeveloped a real-time chat application using FastAPI, Firebase, and React with secure authentication and'),\n",
       " Document(metadata={'producer': 'Skia/PDF m141', 'creator': 'FlowCV - https://flowcv.com', 'creationdate': '2025-11-19T11:01:31+00:00', 'moddate': '2025-11-19T11:01:31+00:00', 'keywords': 'FlowCV – Online Resume Builder – https://flowcv.com', 'source': '../data/pdf/RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf', 'file_type': 'pdf'}, page_content='AI Agents : Google\\nPython coder badge : Google\\nPROJECTS\\nRealtime chatting Application\\nDeveloped a real-time chat application using FastAPI, Firebase, and React with secure authentication and \\ninstant messaging features. Integrated OpenAI to provide AI-powered smart responses and chat assistance \\nfor an enhanced user experience.\\nShowroom Management System\\nDeveloped an AI-enhanced showroom management system using FastAPI as the backend and Streamlit for \\nan intuitive user interface. Integrated MCP servers (Context7) and Gemini CLI to enable advanced AI-\\ndriven task automation, data retrieval, and intelligent decision support. Implemented tools and workflows \\nusing Speckit to define system rules, plans, and operations, enabling streamlined inventory management, \\nproduct tracking, customer assistance, and staff task coordination. \\nEDUCATION\\nBachelor of Engineering (B.E.) - Artificial Intelligence and Machine Learning\\nSavitribai Phule Pune University, Pune\\n08/2022 – 07/2025\\nPune,India'),\n",
       " Document(metadata={'producer': 'Skia/PDF m141', 'creator': 'FlowCV - https://flowcv.com', 'creationdate': '2025-11-19T11:01:31+00:00', 'moddate': '2025-11-19T11:01:31+00:00', 'keywords': 'FlowCV – Online Resume Builder – https://flowcv.com', 'source': '../data/pdf/RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf', 'file_type': 'pdf'}, page_content='EDUCATION\\nBachelor of Engineering (B.E.) - Artificial Intelligence and Machine Learning\\nSavitribai Phule Pune University, Pune\\n08/2022 – 07/2025\\nPune,India\\nPost Graduate (Diploma)- Computer Science\\nMaharashtra State Board Of Technical Education\\n07/2020 – 06/2022\\nKolhapur,Maharashtra')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bde24ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 3 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (3, 384)\n",
      "Adding 3 documents to vector store...\n",
      "Successfully added 3 documents to vector store\n",
      "Total documents in collection: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Convert the text to embeddings\n",
    "texts=[doc.page_content for doc in chunks]\n",
    "\n",
    "## Generate the Embeddings\n",
    "\n",
    "embeddings=embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "##store int he vector dtaabase\n",
    "vectorstore.add_documents(chunks,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498acd10",
   "metadata": {},
   "source": [
    "### Retriever Pipeline From VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f7b0ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    \"\"\"Handles query-based retrieval from the vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "        \"\"\"\n",
    "        Initialize the retriever\n",
    "        \n",
    "        Args:\n",
    "            vector_store: Vector store containing document embeddings\n",
    "            embedding_manager: Manager for generating query embeddings\n",
    "        \"\"\"\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5, score_threshold: float = -1) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for a query\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            top_k: Number of top results to return\n",
    "            score_threshold: Minimum similarity score threshold\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing retrieved documents and metadata\n",
    "        \"\"\"\n",
    "        print(f\"Retrieving documents for query: '{query}'\")\n",
    "        print(f\"Top K: {top_k}, Score threshold: {score_threshold}\")\n",
    "        \n",
    "        # Generate query embedding\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "        \n",
    "        # Search in vector store\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k\n",
    "            )\n",
    "            \n",
    "            # Process results\n",
    "            retrieved_docs = []\n",
    "            \n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "                \n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                    # Convert distance to similarity score (ChromaDB uses cosine distance)\n",
    "                    similarity_score = 1 - distance\n",
    "\n",
    "                    print(\"similarity_score:\",similarity_score)\n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i + 1\n",
    "                        })\n",
    "                \n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "            \n",
    "            return retrieved_docs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "\n",
    "rag_retriever=RAGRetriever(vectorstore,embedding_manager)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "351730b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RAGRetriever at 0x12dca3c10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7e78529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'what skill RUSHIKESH has'\n",
      "Top K: 5, Score threshold: -1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "similarity_score: -0.22010362148284912\n",
      "similarity_score: -0.7922244071960449\n",
      "similarity_score: -0.8385517597198486\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_9631ae84_0',\n",
       "  'content': 'RUSHIKESH MORE\\npython developer\\nrushismore7777@gmail.com\\n \\n+919067717776\\n \\nKolhapur,Maharashtra,India\\n \\nlinkedin.com/in/rushikesh-more-2879182a8\\n \\ngithub.com/RushikeshMore66\\n \\nPROFILE\\nPython Developer with a strong foundation in Computer Science and AI/ML. Skilled in FastAPI, LangChain,\\nMCP servers, and LLM integrations for building intelligent applications. Currently expanding my expertise\\nin advanced Python development and modern AI frameworks. Passionate about creating scalable AI\\nsolutions and continuously growing as a developer.\\nSKILLS\\n•Programming languages : Python\\n•Cloud : Git\\n•Frameworks & Tools : FastAPI, Streamlit\\n•Soft skill : Attention To Detail , Creative Thinking ,Team Collaboration, Time Management\\nCERTIFICATES\\nAI Agents : Google\\nPython coder badge : Google\\nPROJECTS\\nRealtime chatting Application\\nDeveloped a real-time chat application using FastAPI, Firebase, and React with secure authentication and',\n",
       "  'metadata': {'producer': 'Skia/PDF m141',\n",
       "   'creator': 'FlowCV - https://flowcv.com',\n",
       "   'page': 0,\n",
       "   'source': '../data/pdf/RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf',\n",
       "   'total_pages': 1,\n",
       "   'content_length': 927,\n",
       "   'file_type': 'pdf',\n",
       "   'keywords': 'FlowCV – Online Resume Builder – https://flowcv.com',\n",
       "   'source_file': 'RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf',\n",
       "   'doc_index': 0,\n",
       "   'creationdate': '2025-11-19T11:01:31+00:00',\n",
       "   'page_label': '1',\n",
       "   'moddate': '2025-11-19T11:01:31+00:00'},\n",
       "  'similarity_score': -0.22010362148284912,\n",
       "  'distance': 1.2201036214828491,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_192297b2_2',\n",
       "  'content': 'EDUCATION\\nBachelor of Engineering (B.E.) - Artificial Intelligence and Machine Learning\\nSavitribai Phule Pune University, Pune\\n08/2022 – 07/2025\\nPune,India\\nPost Graduate (Diploma)- Computer Science\\nMaharashtra State Board Of Technical Education\\n07/2020 – 06/2022\\nKolhapur,Maharashtra',\n",
       "  'metadata': {'file_type': 'pdf',\n",
       "   'page_label': '1',\n",
       "   'producer': 'Skia/PDF m141',\n",
       "   'keywords': 'FlowCV – Online Resume Builder – https://flowcv.com',\n",
       "   'creator': 'FlowCV - https://flowcv.com',\n",
       "   'page': 0,\n",
       "   'creationdate': '2025-11-19T11:01:31+00:00',\n",
       "   'doc_index': 2,\n",
       "   'total_pages': 1,\n",
       "   'source': '../data/pdf/RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf',\n",
       "   'content_length': 283,\n",
       "   'moddate': '2025-11-19T11:01:31+00:00',\n",
       "   'source_file': 'RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf'},\n",
       "  'similarity_score': -0.7922244071960449,\n",
       "  'distance': 1.792224407196045,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_0996701f_1',\n",
       "  'content': 'AI Agents : Google\\nPython coder badge : Google\\nPROJECTS\\nRealtime chatting Application\\nDeveloped a real-time chat application using FastAPI, Firebase, and React with secure authentication and \\ninstant messaging features. Integrated OpenAI to provide AI-powered smart responses and chat assistance \\nfor an enhanced user experience.\\nShowroom Management System\\nDeveloped an AI-enhanced showroom management system using FastAPI as the backend and Streamlit for \\nan intuitive user interface. Integrated MCP servers (Context7) and Gemini CLI to enable advanced AI-\\ndriven task automation, data retrieval, and intelligent decision support. Implemented tools and workflows \\nusing Speckit to define system rules, plans, and operations, enabling streamlined inventory management, \\nproduct tracking, customer assistance, and staff task coordination. \\nEDUCATION\\nBachelor of Engineering (B.E.) - Artificial Intelligence and Machine Learning\\nSavitribai Phule Pune University, Pune\\n08/2022 – 07/2025\\nPune,India',\n",
       "  'metadata': {'total_pages': 1,\n",
       "   'moddate': '2025-11-19T11:01:31+00:00',\n",
       "   'source': '../data/pdf/RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf',\n",
       "   'source_file': 'RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf',\n",
       "   'creationdate': '2025-11-19T11:01:31+00:00',\n",
       "   'content_length': 994,\n",
       "   'producer': 'Skia/PDF m141',\n",
       "   'doc_index': 1,\n",
       "   'page_label': '1',\n",
       "   'keywords': 'FlowCV – Online Resume Builder – https://flowcv.com',\n",
       "   'page': 0,\n",
       "   'creator': 'FlowCV - https://flowcv.com',\n",
       "   'file_type': 'pdf'},\n",
       "  'similarity_score': -0.8385517597198486,\n",
       "  'distance': 1.8385517597198486,\n",
       "  'rank': 3}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"what skill RUSHIKESH has\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d8141ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Tell me about RUSHIKESH'\n",
      "Top K: 5, Score threshold: -1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "similarity_score: -0.2656254768371582\n",
      "similarity_score: -0.8616278171539307\n",
      "similarity_score: -0.897167444229126\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_9631ae84_0',\n",
       "  'content': 'RUSHIKESH MORE\\npython developer\\nrushismore7777@gmail.com\\n \\n+919067717776\\n \\nKolhapur,Maharashtra,India\\n \\nlinkedin.com/in/rushikesh-more-2879182a8\\n \\ngithub.com/RushikeshMore66\\n \\nPROFILE\\nPython Developer with a strong foundation in Computer Science and AI/ML. Skilled in FastAPI, LangChain,\\nMCP servers, and LLM integrations for building intelligent applications. Currently expanding my expertise\\nin advanced Python development and modern AI frameworks. Passionate about creating scalable AI\\nsolutions and continuously growing as a developer.\\nSKILLS\\n•Programming languages : Python\\n•Cloud : Git\\n•Frameworks & Tools : FastAPI, Streamlit\\n•Soft skill : Attention To Detail , Creative Thinking ,Team Collaboration, Time Management\\nCERTIFICATES\\nAI Agents : Google\\nPython coder badge : Google\\nPROJECTS\\nRealtime chatting Application\\nDeveloped a real-time chat application using FastAPI, Firebase, and React with secure authentication and',\n",
       "  'metadata': {'moddate': '2025-11-19T11:01:31+00:00',\n",
       "   'creator': 'FlowCV - https://flowcv.com',\n",
       "   'source': '../data/pdf/RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf',\n",
       "   'creationdate': '2025-11-19T11:01:31+00:00',\n",
       "   'file_type': 'pdf',\n",
       "   'doc_index': 0,\n",
       "   'producer': 'Skia/PDF m141',\n",
       "   'source_file': 'RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf',\n",
       "   'content_length': 927,\n",
       "   'keywords': 'FlowCV – Online Resume Builder – https://flowcv.com',\n",
       "   'total_pages': 1,\n",
       "   'page_label': '1',\n",
       "   'page': 0},\n",
       "  'similarity_score': -0.2656254768371582,\n",
       "  'distance': 1.2656254768371582,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_0996701f_1',\n",
       "  'content': 'AI Agents : Google\\nPython coder badge : Google\\nPROJECTS\\nRealtime chatting Application\\nDeveloped a real-time chat application using FastAPI, Firebase, and React with secure authentication and \\ninstant messaging features. Integrated OpenAI to provide AI-powered smart responses and chat assistance \\nfor an enhanced user experience.\\nShowroom Management System\\nDeveloped an AI-enhanced showroom management system using FastAPI as the backend and Streamlit for \\nan intuitive user interface. Integrated MCP servers (Context7) and Gemini CLI to enable advanced AI-\\ndriven task automation, data retrieval, and intelligent decision support. Implemented tools and workflows \\nusing Speckit to define system rules, plans, and operations, enabling streamlined inventory management, \\nproduct tracking, customer assistance, and staff task coordination. \\nEDUCATION\\nBachelor of Engineering (B.E.) - Artificial Intelligence and Machine Learning\\nSavitribai Phule Pune University, Pune\\n08/2022 – 07/2025\\nPune,India',\n",
       "  'metadata': {'moddate': '2025-11-19T11:01:31+00:00',\n",
       "   'source': '../data/pdf/RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf',\n",
       "   'source_file': 'RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf',\n",
       "   'producer': 'Skia/PDF m141',\n",
       "   'content_length': 994,\n",
       "   'keywords': 'FlowCV – Online Resume Builder – https://flowcv.com',\n",
       "   'creator': 'FlowCV - https://flowcv.com',\n",
       "   'page': 0,\n",
       "   'total_pages': 1,\n",
       "   'doc_index': 1,\n",
       "   'page_label': '1',\n",
       "   'file_type': 'pdf',\n",
       "   'creationdate': '2025-11-19T11:01:31+00:00'},\n",
       "  'similarity_score': -0.8616278171539307,\n",
       "  'distance': 1.8616278171539307,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_192297b2_2',\n",
       "  'content': 'EDUCATION\\nBachelor of Engineering (B.E.) - Artificial Intelligence and Machine Learning\\nSavitribai Phule Pune University, Pune\\n08/2022 – 07/2025\\nPune,India\\nPost Graduate (Diploma)- Computer Science\\nMaharashtra State Board Of Technical Education\\n07/2020 – 06/2022\\nKolhapur,Maharashtra',\n",
       "  'metadata': {'source': '../data/pdf/RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf',\n",
       "   'page_label': '1',\n",
       "   'page': 0,\n",
       "   'source_file': 'RUSHIKESH-MORE-FlowCV-Resume-20251119.pdf',\n",
       "   'file_type': 'pdf',\n",
       "   'total_pages': 1,\n",
       "   'content_length': 283,\n",
       "   'keywords': 'FlowCV – Online Resume Builder – https://flowcv.com',\n",
       "   'doc_index': 2,\n",
       "   'creationdate': '2025-11-19T11:01:31+00:00',\n",
       "   'moddate': '2025-11-19T11:01:31+00:00',\n",
       "   'creator': 'FlowCV - https://flowcv.com',\n",
       "   'producer': 'Skia/PDF m141'},\n",
       "  'similarity_score': -0.897167444229126,\n",
       "  'distance': 1.897167444229126,\n",
       "  'rank': 3}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"Tell me about RUSHIKESH\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce23783e",
   "metadata": {},
   "source": [
    "### RAG Pipeline- VectorDB To LLM Output Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a65c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(os.getenv(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba4b617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40bba05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroqLLM:\n",
    "    def __init__(self, model_name: str = \"gemma2-9b-it\", api_key: str =None):\n",
    "        \"\"\"\n",
    "        Initialize Groq LLM\n",
    "        \n",
    "        Args:\n",
    "            model_name: Groq model name (qwen2-72b-instruct, llama3-70b-8192, etc.)\n",
    "            api_key: Groq API key (or set GROQ_API_KEY environment variable)\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.api_key = api_key or os.environ.get(\"GROQ_API_KEY\")\n",
    "        \n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"Groq API key is required. Set GROQ_API_KEY environment variable or pass api_key parameter.\")\n",
    "        \n",
    "        self.llm = ChatGroq(\n",
    "            groq_api_key=self.api_key,\n",
    "            model_name=self.model_name,\n",
    "            temperature=0.1,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "        \n",
    "        print(f\"Initialized Groq LLM with model: {self.model_name}\")\n",
    "\n",
    "    def generate_response(self, query: str, context: str, max_length: int = 500) -> str:\n",
    "        \"\"\"\n",
    "        Generate response using retrieved context\n",
    "        \n",
    "        Args:\n",
    "            query: User question\n",
    "            context: Retrieved document context\n",
    "            max_length: Maximum response length\n",
    "            \n",
    "        Returns:\n",
    "            Generated response string\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create prompt template\n",
    "        prompt_template = PromptTemplate(\n",
    "            input_variables=[\"context\", \"question\"],\n",
    "            template=\"\"\"You are a helpful AI assistant. Use the following context to answer the question accurately and concisely.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: Provide a clear and informative answer based on the context above. If the context doesn't contain enough information to answer the question, say so.\"\"\"\n",
    "        )\n",
    "        \n",
    "        # Format the prompt\n",
    "        formatted_prompt = prompt_template.format(context=context, question=query)\n",
    "        \n",
    "        try:\n",
    "            # Generate response\n",
    "            messages = [HumanMessage(content=formatted_prompt)]\n",
    "            response = self.llm.invoke(messages)\n",
    "            return response.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\"\n",
    "        \n",
    "    def generate_response_simple(self, query: str, context: str) -> str:\n",
    "        \"\"\"\n",
    "        Simple response generation without complex prompting\n",
    "        \n",
    "        Args:\n",
    "            query: User question\n",
    "            context: Retrieved context\n",
    "            \n",
    "        Returns:\n",
    "            Generated response\n",
    "        \"\"\"\n",
    "        simple_prompt = f\"\"\"Based on this context: {context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            messages = [HumanMessage(content=simple_prompt)]\n",
    "            response = self.llm.invoke(messages)\n",
    "            return response.content\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fc0f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Groq LLM with model: gemma2-9b-it\n",
      "Groq LLM initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Groq LLM (you'll need to set GROQ_API_KEY environment variable)\n",
    "try:\n",
    "    groq_llm = GroqLLM(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "    print(\"Groq LLM initialized successfully!\")\n",
    "except ValueError as e:\n",
    "    print(f\"Warning: {e}\")\n",
    "    print(\"Please set your GROQ_API_KEY environment variable to use the LLM.\")\n",
    "    groq_llm = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4110c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Unified Multi-task Learning Framework'\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 5 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_bd5cc745_61',\n",
       "  'content': 'erage scores on CMTEB[ 22] and MTEB[ 23] benchmarks, ranking ﬁrst overall on both\\nCMTEB and MTEB leaderboards, demonstrating the eﬀectiveness o f our approach.\\nThe contributions of our work are summarized as follows:\\n• We propose a uniﬁed multi-task learning framework that systematic ally coordi-\\nnates both data processing and training pipelines, enhancing divers ity in datasets\\nand eﬃciency in model training ;\\n• We develop advanced data synthesis techniques powered by LLM, in cluding Para-\\nphrasing, Data augmentation, and Hard negative generation. The se methods\\nsigniﬁcantly enhance the quality of training corpora, thereby impro ving model’s\\nrobustness and generalization capabilities;\\n• We emply a two-stage training paradigm: Stage 1 focuses exclusively on retrieval\\ncapability building, establishing strong foundational retrieval perf ormance; and\\nstage 2 implements balanced training with controled retrieval/non-r etrieval task',\n",
       "  'metadata': {'creationdate': '2025-09-01T00:50:53+00:00',\n",
       "   'creator': 'arXiv GenPDF (tex2pdf:)',\n",
       "   'source_file': 'emneddings.pdf',\n",
       "   'file_type': 'pdf',\n",
       "   'title': 'QZhou-Embedding Technical Report',\n",
       "   'keywords': '',\n",
       "   'arxivid': 'https://arxiv.org/abs/2508.21632v1',\n",
       "   'total_pages': 27,\n",
       "   'author': 'Peng Yu; En Xu; Bin Chen; Haibiao Chen; Yinfei Xu',\n",
       "   'page_label': '3',\n",
       "   'moddate': '2025-09-01T00:50:53+00:00',\n",
       "   'doi': 'https://doi.org/10.48550/arXiv.2508.21632',\n",
       "   'content_length': 941,\n",
       "   'producer': 'pikepdf 8.15.1',\n",
       "   'page': 2,\n",
       "   'doc_index': 61,\n",
       "   'license': 'http://creativecommons.org/licenses/by/4.0/',\n",
       "   'source': '..\\\\data\\\\pdf\\\\emneddings.pdf'},\n",
       "  'similarity_score': 0.13801008462905884,\n",
       "  'distance': 0.8619899153709412,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_442dbe7b_61',\n",
       "  'content': 'erage scores on CMTEB[ 22] and MTEB[ 23] benchmarks, ranking ﬁrst overall on both\\nCMTEB and MTEB leaderboards, demonstrating the eﬀectiveness o f our approach.\\nThe contributions of our work are summarized as follows:\\n• We propose a uniﬁed multi-task learning framework that systematic ally coordi-\\nnates both data processing and training pipelines, enhancing divers ity in datasets\\nand eﬃciency in model training ;\\n• We develop advanced data synthesis techniques powered by LLM, in cluding Para-\\nphrasing, Data augmentation, and Hard negative generation. The se methods\\nsigniﬁcantly enhance the quality of training corpora, thereby impro ving model’s\\nrobustness and generalization capabilities;\\n• We emply a two-stage training paradigm: Stage 1 focuses exclusively on retrieval\\ncapability building, establishing strong foundational retrieval perf ormance; and\\nstage 2 implements balanced training with controled retrieval/non-r etrieval task',\n",
       "  'metadata': {'total_pages': 27,\n",
       "   'file_type': 'pdf',\n",
       "   'doc_index': 61,\n",
       "   'title': 'QZhou-Embedding Technical Report',\n",
       "   'keywords': '',\n",
       "   'content_length': 941,\n",
       "   'doi': 'https://doi.org/10.48550/arXiv.2508.21632',\n",
       "   'page': 2,\n",
       "   'page_label': '3',\n",
       "   'producer': 'pikepdf 8.15.1',\n",
       "   'author': 'Peng Yu; En Xu; Bin Chen; Haibiao Chen; Yinfei Xu',\n",
       "   'source': '..\\\\data\\\\pdf\\\\emneddings.pdf',\n",
       "   'creationdate': '2025-09-01T00:50:53+00:00',\n",
       "   'creator': 'arXiv GenPDF (tex2pdf:)',\n",
       "   'arxivid': 'https://arxiv.org/abs/2508.21632v1',\n",
       "   'source_file': 'emneddings.pdf',\n",
       "   'license': 'http://creativecommons.org/licenses/by/4.0/',\n",
       "   'moddate': '2025-09-01T00:50:53+00:00'},\n",
       "  'similarity_score': 0.13801008462905884,\n",
       "  'distance': 0.8619899153709412,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_45e2cfa9_61',\n",
       "  'content': 'erage scores on CMTEB[ 22] and MTEB[ 23] benchmarks, ranking ﬁrst overall on both\\nCMTEB and MTEB leaderboards, demonstrating the eﬀectiveness o f our approach.\\nThe contributions of our work are summarized as follows:\\n• We propose a uniﬁed multi-task learning framework that systematic ally coordi-\\nnates both data processing and training pipelines, enhancing divers ity in datasets\\nand eﬃciency in model training ;\\n• We develop advanced data synthesis techniques powered by LLM, in cluding Para-\\nphrasing, Data augmentation, and Hard negative generation. The se methods\\nsigniﬁcantly enhance the quality of training corpora, thereby impro ving model’s\\nrobustness and generalization capabilities;\\n• We emply a two-stage training paradigm: Stage 1 focuses exclusively on retrieval\\ncapability building, establishing strong foundational retrieval perf ormance; and\\nstage 2 implements balanced training with controled retrieval/non-r etrieval task',\n",
       "  'metadata': {'producer': 'pikepdf 8.15.1',\n",
       "   'keywords': '',\n",
       "   'doi': 'https://doi.org/10.48550/arXiv.2508.21632',\n",
       "   'source': '..\\\\data\\\\pdf\\\\emneddings.pdf',\n",
       "   'arxivid': 'https://arxiv.org/abs/2508.21632v1',\n",
       "   'creationdate': '2025-09-01T00:50:53+00:00',\n",
       "   'moddate': '2025-09-01T00:50:53+00:00',\n",
       "   'total_pages': 27,\n",
       "   'content_length': 941,\n",
       "   'page': 2,\n",
       "   'doc_index': 61,\n",
       "   'source_file': 'emneddings.pdf',\n",
       "   'creator': 'arXiv GenPDF (tex2pdf:)',\n",
       "   'file_type': 'pdf',\n",
       "   'license': 'http://creativecommons.org/licenses/by/4.0/',\n",
       "   'page_label': '3',\n",
       "   'author': 'Peng Yu; En Xu; Bin Chen; Haibiao Chen; Yinfei Xu',\n",
       "   'title': 'QZhou-Embedding Technical Report'},\n",
       "  'similarity_score': 0.13801008462905884,\n",
       "  'distance': 0.8619899153709412,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_3497d198_71',\n",
       "  'content': 'and Conan-Embedding-v2 have incorporated multi-task learning us ing diverse train-\\ning data with varying label processing methods, some employing task -speciﬁc losses\\n(InfoNCE[48], Cosent[ 49], etc.).\\nOur design principle aims to accommodate more tasks and data types , enabling cross-\\ndomain and cross-task data to eﬀectively enhance embedding capa bilities. We propose\\na uniﬁed multi-task learning framework that categorizes training da ta into three task\\ntypes: retrieval, NLI, and classiﬁcation, with customized data and training solutions\\nfor each, allowing most natural text data to be converted into emb edding training data\\nthrough this framework. The following sections detail the framewo rk’s components and\\nimplementation methods.\\n3.1 Model Architecture\\nEmbedding models based on BERT or T5 [\\n39][15][50][24] exhibit powerful contextual\\nrepresentation capabilities, primarily attributed to their bidirection al attention mech-',\n",
       "  'metadata': {'moddate': '2025-09-01T00:50:53+00:00',\n",
       "   'title': 'QZhou-Embedding Technical Report',\n",
       "   'page': 4,\n",
       "   'doi': 'https://doi.org/10.48550/arXiv.2508.21632',\n",
       "   'source_file': 'emneddings.pdf',\n",
       "   'arxivid': 'https://arxiv.org/abs/2508.21632v1',\n",
       "   'author': 'Peng Yu; En Xu; Bin Chen; Haibiao Chen; Yinfei Xu',\n",
       "   'page_label': '5',\n",
       "   'file_type': 'pdf',\n",
       "   'producer': 'pikepdf 8.15.1',\n",
       "   'source': '..\\\\data\\\\pdf\\\\emneddings.pdf',\n",
       "   'license': 'http://creativecommons.org/licenses/by/4.0/',\n",
       "   'total_pages': 27,\n",
       "   'content_length': 937,\n",
       "   'doc_index': 71,\n",
       "   'creator': 'arXiv GenPDF (tex2pdf:)',\n",
       "   'creationdate': '2025-09-01T00:50:53+00:00',\n",
       "   'keywords': ''},\n",
       "  'similarity_score': 0.10624760389328003,\n",
       "  'distance': 0.89375239610672,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_bb00aef7_71',\n",
       "  'content': 'and Conan-Embedding-v2 have incorporated multi-task learning us ing diverse train-\\ning data with varying label processing methods, some employing task -speciﬁc losses\\n(InfoNCE[48], Cosent[ 49], etc.).\\nOur design principle aims to accommodate more tasks and data types , enabling cross-\\ndomain and cross-task data to eﬀectively enhance embedding capa bilities. We propose\\na uniﬁed multi-task learning framework that categorizes training da ta into three task\\ntypes: retrieval, NLI, and classiﬁcation, with customized data and training solutions\\nfor each, allowing most natural text data to be converted into emb edding training data\\nthrough this framework. The following sections detail the framewo rk’s components and\\nimplementation methods.\\n3.1 Model Architecture\\nEmbedding models based on BERT or T5 [\\n39][15][50][24] exhibit powerful contextual\\nrepresentation capabilities, primarily attributed to their bidirection al attention mech-',\n",
       "  'metadata': {'total_pages': 27,\n",
       "   'author': 'Peng Yu; En Xu; Bin Chen; Haibiao Chen; Yinfei Xu',\n",
       "   'source': '..\\\\data\\\\pdf\\\\emneddings.pdf',\n",
       "   'creationdate': '2025-09-01T00:50:53+00:00',\n",
       "   'content_length': 937,\n",
       "   'page': 4,\n",
       "   'moddate': '2025-09-01T00:50:53+00:00',\n",
       "   'license': 'http://creativecommons.org/licenses/by/4.0/',\n",
       "   'title': 'QZhou-Embedding Technical Report',\n",
       "   'arxivid': 'https://arxiv.org/abs/2508.21632v1',\n",
       "   'creator': 'arXiv GenPDF (tex2pdf:)',\n",
       "   'doi': 'https://doi.org/10.48550/arXiv.2508.21632',\n",
       "   'file_type': 'pdf',\n",
       "   'producer': 'pikepdf 8.15.1',\n",
       "   'source_file': 'emneddings.pdf',\n",
       "   'doc_index': 71,\n",
       "   'page_label': '5',\n",
       "   'keywords': ''},\n",
       "  'similarity_score': 0.10624760389328003,\n",
       "  'distance': 0.89375239610672,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### get the context from the retriever and pass it to the LLM\n",
    "\n",
    "rag_retriever.retrieve(\"Unified Multi-task Learning Framework\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea465ac",
   "metadata": {},
   "source": [
    "### Integration Vectordb Context pipeline With LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a950a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple RAG pipeline with Groq LLM\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "### Initialize the Groq LLM (set your GROQ_API_KEY in environment)\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"gemma2-9b-it\",temperature=0.1,max_tokens=1024)\n",
    "\n",
    "## 2. Simple RAG function: retrieve context + generate response\n",
    "def rag_simple(query,retriever,llm,top_k=3):\n",
    "    ## retriever the context\n",
    "    results=retriever.retrieve(query,top_k=top_k)\n",
    "    context=\"\\n\\n\".join([doc['content'] for doc in results]) if results else \"\"\n",
    "    if not context:\n",
    "        return \"No relevant context found to answer the question.\"\n",
    "    \n",
    "    ## generate the answwer using GROQ LLM\n",
    "    prompt=f\"\"\"Use the following context to answer the question concisely.\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question: {query}\n",
    "\n",
    "        Answer:\"\"\"\n",
    "    \n",
    "    response=llm.invoke([prompt.format(context=context,query=query)])\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df1bf366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is attention mechanism?'\n",
      "Top K: 3, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An attention mechanism is a function that maps a query and a set of key-value pairs to an output vector, using a weighted sum of the values.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer=rag_simple(\"What is attention mechanism?\",rag_retriever,llm)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6857b1c2",
   "metadata": {},
   "source": [
    "### Enhanced RAG Pipeline Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2832fd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Hard Negative Mining Technqiues'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The text describes several hard negative mining techniques used in contrastive learning for retrieval models:\n",
      "\n",
      "* **ANCE:** Uses asynchronous ANN indexing and checkpoint states to periodically update hard negatives.\n",
      "* **Conan-Embedding:** Employs a dynamic strategy, excluding and refreshing samples based on score thresholds.\n",
      "* **NV-Retriever:**  Proposes positive-aware mining with TopK-MarginPos and TopKPercPos filtering to reduce false negatives.\n",
      "* **LGAI-Embedding:** Builds on NV-Retriever, using ANNA IR as a teacher model to identify high-quality hard negatives and TopKPercPos filtering. \n",
      "\n",
      "\n",
      "\n",
      "Sources: [{'source': 'emneddings.pdf', 'page': 4, 'score': 0.18709993362426758, 'preview': 'QZhou-Embedding Technical Report\\n Kingsoft AI\\n2.4 Hard Negative Mining Techniques\\nHard negatives serve as essential components in contrastive lear ning for retrieval model\\ntraining. Early work like ANCE[\\n46] proposed an asynchronous ANN indexing mech-\\nanism that periodically updates hard negatives u...'}, {'source': 'emneddings.pdf', 'page': 4, 'score': 0.18709993362426758, 'preview': 'QZhou-Embedding Technical Report\\n Kingsoft AI\\n2.4 Hard Negative Mining Techniques\\nHard negatives serve as essential components in contrastive lear ning for retrieval model\\ntraining. Early work like ANCE[\\n46] proposed an asynchronous ANN indexing mech-\\nanism that periodically updates hard negatives u...'}, {'source': 'emneddings.pdf', 'page': 4, 'score': 0.18709993362426758, 'preview': 'QZhou-Embedding Technical Report\\n Kingsoft AI\\n2.4 Hard Negative Mining Techniques\\nHard negatives serve as essential components in contrastive lear ning for retrieval model\\ntraining. Early work like ANCE[\\n46] proposed an asynchronous ANN indexing mech-\\nanism that periodically updates hard negatives u...'}]\n",
      "Confidence: 0.18709993362426758\n",
      "Context Preview: QZhou-Embedding Technical Report\n",
      " Kingsoft AI\n",
      "2.4 Hard Negative Mining Techniques\n",
      "Hard negatives serve as essential components in contrastive lear ning for retrieval model\n",
      "training. Early work like ANCE[\n",
      "46] proposed an asynchronous ANN indexing mech-\n",
      "anism that periodically updates hard negatives u\n"
     ]
    }
   ],
   "source": [
    "# --- Enhanced RAG Pipeline Features ---\n",
    "def rag_advanced(query, retriever, llm, top_k=5, min_score=0.2, return_context=False):\n",
    "    \"\"\"\n",
    "    RAG pipeline with extra features:\n",
    "    - Returns answer, sources, confidence score, and optionally full context.\n",
    "    \"\"\"\n",
    "    results = retriever.retrieve(query, top_k=top_k, score_threshold=min_score)\n",
    "    if not results:\n",
    "        return {'answer': 'No relevant context found.', 'sources': [], 'confidence': 0.0, 'context': ''}\n",
    "    \n",
    "    # Prepare context and sources\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "    sources = [{\n",
    "        'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "        'page': doc['metadata'].get('page', 'unknown'),\n",
    "        'score': doc['similarity_score'],\n",
    "        'preview': doc['content'][:300] + '...'\n",
    "    } for doc in results]\n",
    "    confidence = max([doc['similarity_score'] for doc in results])\n",
    "    \n",
    "    # Generate answer\n",
    "    prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\"\"\n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "    \n",
    "    output = {\n",
    "        'answer': response.content,\n",
    "        'sources': sources,\n",
    "        'confidence': confidence\n",
    "    }\n",
    "    if return_context:\n",
    "        output['context'] = context\n",
    "    return output\n",
    "\n",
    "# Example usage:\n",
    "result = rag_advanced(\"Hard Negative Mining Technqiues\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa6150d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'what is attention is all you need'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n",
      "Streaming answer:\n",
      "Use the following context to answer the question concisely.\n",
      "Context:\n",
      "3.2 Attention\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
      "3\n",
      "\n",
      "3.2 Attention\n",
      "An attention functi"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
      "3\n",
      "\n",
      "3.2 Attention\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
      "3\n",
      "\n",
      "Question: what is attention is all you need\n",
      "\n",
      "Answer:\n",
      "\n",
      "Final Answer: \"Attention Is All You Need\" is a paper that introduced the Transformer model, which relies solely on attention mechanisms for sequence transduction tasks, eliminating the need for recurrent or convolutional networks.  \n",
      "\n",
      "\n",
      "Citations:\n",
      "[1] attention.pdf (page 2)\n",
      "[2] attention.pdf (page 2)\n",
      "[3] attention.pdf (page 2)\n",
      "Summary: The paper \"Attention Is All You Need\" introduced the Transformer model, a novel architecture for sequence transduction tasks.  This model utilizes only attention mechanisms, dispensing with traditional recurrent or convolutional networks. \n",
      "\n",
      "\n",
      "\n",
      "History: {'question': 'what is attention is all you need', 'answer': '\"Attention Is All You Need\" is a paper that introduced the Transformer model, which relies solely on attention mechanisms for sequence transduction tasks, eliminating the need for recurrent or convolutional networks.  \\n', 'sources': [{'source': 'attention.pdf', 'page': 2, 'score': 0.1399550437927246, 'preview': '3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere...'}, {'source': 'attention.pdf', 'page': 2, 'score': 0.1399550437927246, 'preview': '3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere...'}, {'source': 'attention.pdf', 'page': 2, 'score': 0.1399550437927246, 'preview': '3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere...'}], 'summary': 'The paper \"Attention Is All You Need\" introduced the Transformer model, a novel architecture for sequence transduction tasks.  This model utilizes only attention mechanisms, dispensing with traditional recurrent or convolutional networks. \\n\\n\\n'}\n"
     ]
    }
   ],
   "source": [
    "# --- Advanced RAG Pipeline: Streaming, Citations, History, Summarization ---\n",
    "from typing import List, Dict, Any\n",
    "import time\n",
    "\n",
    "class AdvancedRAGPipeline:\n",
    "    def __init__(self, retriever, llm):\n",
    "        self.retriever = retriever\n",
    "        self.llm = llm\n",
    "        self.history = []  # Store query history\n",
    "\n",
    "    def query(self, question: str, top_k: int = 5, min_score: float = 0.2, stream: bool = False, summarize: bool = False) -> Dict[str, Any]:\n",
    "        # Retrieve relevant documents\n",
    "        results = self.retriever.retrieve(question, top_k=top_k, score_threshold=min_score)\n",
    "        if not results:\n",
    "            answer = \"No relevant context found.\"\n",
    "            sources = []\n",
    "            context = \"\"\n",
    "        else:\n",
    "            context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "            sources = [{\n",
    "                'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "                'page': doc['metadata'].get('page', 'unknown'),\n",
    "                'score': doc['similarity_score'],\n",
    "                'preview': doc['content'][:120] + '...'\n",
    "            } for doc in results]\n",
    "            # Streaming answer simulation\n",
    "            prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\"\"\n",
    "            if stream:\n",
    "                print(\"Streaming answer:\")\n",
    "                for i in range(0, len(prompt), 80):\n",
    "                    print(prompt[i:i+80], end='', flush=True)\n",
    "                    time.sleep(0.05)\n",
    "                print()\n",
    "            response = self.llm.invoke([prompt.format(context=context, question=question)])\n",
    "            answer = response.content\n",
    "\n",
    "        # Add citations to answer\n",
    "        citations = [f\"[{i+1}] {src['source']} (page {src['page']})\" for i, src in enumerate(sources)]\n",
    "        answer_with_citations = answer + \"\\n\\nCitations:\\n\" + \"\\n\".join(citations) if citations else answer\n",
    "\n",
    "        # Optionally summarize answer\n",
    "        summary = None\n",
    "        if summarize and answer:\n",
    "            summary_prompt = f\"Summarize the following answer in 2 sentences:\\n{answer}\"\n",
    "            summary_resp = self.llm.invoke([summary_prompt])\n",
    "            summary = summary_resp.content\n",
    "\n",
    "        # Store query history\n",
    "        self.history.append({\n",
    "            'question': question,\n",
    "            'answer': answer,\n",
    "            'sources': sources,\n",
    "            'summary': summary\n",
    "        })\n",
    "\n",
    "        return {\n",
    "            'question': question,\n",
    "            'answer': answer_with_citations,\n",
    "            'sources': sources,\n",
    "            'summary': summary,\n",
    "            'history': self.history\n",
    "        }\n",
    "\n",
    "# Example usage:\n",
    "adv_rag = AdvancedRAGPipeline(rag_retriever, llm)\n",
    "result = adv_rag.query(\"what is attention is all you need\", top_k=3, min_score=0.1, stream=True, summarize=True)\n",
    "print(\"\\nFinal Answer:\", result['answer'])\n",
    "print(\"Summary:\", result['summary'])\n",
    "print(\"History:\", result['history'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d695e1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG-Tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
